{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os, glob\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import tensorflow.keras as keras\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from grad_cam import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data files for which to get heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and preprocess one case\n",
    "def load_file(path):\n",
    "    \n",
    "    #Load case\n",
    "    data = np.load(path)['arr_0'][0:None:3, 0:None:3, :]\n",
    "        \n",
    "    #Standardise fields\n",
    "    for field in range(data.shape[-1]):\n",
    "        avg_ = np.mean(data[:,:,field])\n",
    "        std_ = np.std(data[:,:,field])\n",
    "        data[:,:,field] = (data[:,:,field] - avg_) / std_ \n",
    "\n",
    "    #Obtain label\n",
    "    name = path.replace(\".npz\", \"\").split(\"/\")[-1]\n",
    "    if \"no\" in name:\n",
    "        cat, start_lat, end_lat, start_lon, end_lon, date = name.split(\"_\")\n",
    "        label = 0\n",
    "    else:\n",
    "        cat, press, wind, start_lat, end_lat, start_lon, end_lon, date = name.split(\"_\")\n",
    "        if int(cat) > 0:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "    #Return preprocessed case and its label\n",
    "    return data, label\n",
    "\n",
    "#Load a number of files\n",
    "def load_data(paths):\n",
    "    \n",
    "    #Open first file in list to get shape of cases\n",
    "    dummy_file = np.load(paths[0])['arr_0'][0:None:3, 0:None:3, :]\n",
    "    \n",
    "    #Create array to hold all the preprocessed cases\n",
    "    data = np.zeros((len(paths), dummy_file.shape[0], dummy_file.shape[1], dummy_file.shape[2]))\n",
    "    \n",
    "    #Create array to hold all the labels for the corresponding cases\n",
    "    labels = np.zeros(len(paths))\n",
    "    \n",
    "    #Load files in parallel\n",
    "    num_cores = np.min([len(paths), int(0.5*mp.cpu_count())])\n",
    "    pool = mp.Pool(num_cores)\n",
    "    res = list(pool.imap(load_file, paths))\n",
    "    for i in range(len(res)):\n",
    "        data[i, :, :, :] = res[i][0]\n",
    "        labels[i] = res[i][1]\n",
    "    pool.close()\n",
    "        \n",
    "    #Return cases and thier labels\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all files available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted(glob.glob(os.path.join(\"/work/scratch/dg/final_data_paper_1\", \"*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get files we are interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for path in all_files:\n",
    "    name = path.split(\"/\")[-1]\n",
    "    \n",
    "    if \"no\" in name:\n",
    "        pass\n",
    "    else:\n",
    "        cat, press, wind, start_lat, end_lat, start_lon, end_lon, date = name.replace(\".npz\", \"\").split(\"_\")\n",
    "        year = int(date[:4])\n",
    "        month = int(date[4:6])\n",
    "        day = int(date[6:8])\n",
    "        hour = int(date[8:])\n",
    "        date_time = dt(year, month, day, hour)\n",
    "        if int(start_lat) == 0 and int(end_lat) == 60 and int(start_lon) == 260 and date_time >= dt(2005, 8, 28, 18) and date_time <= dt(2005, 8, 29, 0):\n",
    "            paths.append(path)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model to generate heatmap for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"/home/users/dgalea/papers/paper1/code/final_data/Section 5 - Discussion/D - Model Generalization/gg.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = load_data(paths)\n",
    "preds = model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and Save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"MSLP\", \"10m wind speed\", \"850hPa Vorticity\", \"700hPa Vorticity\", \"600hPa Vorticity\"]\n",
    "heatmap = get_heatmap(model, \"conv2d_3\", data[0])    \n",
    "name = paths[0].replace(\".npz\", \"\").split(\"/\")[-1]\n",
    "plot_heatmap(heatmap, data[0], preds[0], variables, name, save=True, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
